"""
Utilitaires pour l'analyse des donn√©es fonci√®res DVF
"""

import pandas as pd
import numpy as np
from typing import Dict, List
from scipy import stats
import warnings

warnings.filterwarnings("ignore")


class DVFDataProcessor:
    """
    Classe pour le traitement des donn√©es DVF
    """

    def __init__(self, df: pd.DataFrame):
        """
        Initialise le processeur avec un DataFrame DVF

        Args:
            df: DataFrame contenant les donn√©es DVF
        """
        self.df = df.copy()
        self.original_shape = df.shape

    def clean_data(self, start_year: int = 2019, end_year: int = 2023) -> pd.DataFrame:
        """
        Nettoie les donn√©es DVF selon les crit√®res d√©finis

        Args:
            start_year: Ann√©e de d√©but pour le filtrage
            end_year: Ann√©e de fin pour le filtrage

        Returns:
            DataFrame nettoy√©
        """
        df_clean = self.df.copy()

        # Conversion de la date
        if "date_mutation" in df_clean.columns:
            df_clean["date_mutation"] = pd.to_datetime(df_clean["date_mutation"])
            df_clean["annee_mutation"] = df_clean["date_mutation"].dt.year

            # Filtrage temporel
            df_clean = df_clean[
                (df_clean["annee_mutation"] >= start_year)
                & (df_clean["annee_mutation"] <= end_year)
            ]

        # Nettoyage des valeurs critiques
        critical_cols = ["valeur_fonciere", "surface_reelle_bati"]
        for col in critical_cols:
            if col in df_clean.columns:
                df_clean = df_clean.dropna(subset=[col])
                df_clean = df_clean[df_clean[col] > 0]

        # Calcul du prix au m¬≤
        if all(col in df_clean.columns for col in critical_cols):
            df_clean["prix_m2"] = df_clean["valeur_fonciere"] / df_clean["surface_reelle_bati"]

            # Suppression des outliers extr√™mes (prix au m¬≤ > 50000‚Ç¨ ou < 100‚Ç¨)
            df_clean = df_clean[(df_clean["prix_m2"] >= 100) & (df_clean["prix_m2"] <= 50000)]

        self.df_clean = df_clean
        return df_clean

    def get_cleaning_report(self) -> Dict:
        """
        G√©n√®re un rapport de nettoyage

        Returns:
            Dictionnaire avec les statistiques de nettoyage
        """
        if not hasattr(self, "df_clean"):
            raise ValueError("Veuillez d'abord ex√©cuter clean_data()")

        return {
            "original_rows": self.original_shape[0],
            "cleaned_rows": self.df_clean.shape[0],
            "removed_rows": self.original_shape[0] - self.df_clean.shape[0],
            "removal_percentage": round(
                (self.original_shape[0] - self.df_clean.shape[0]) / self.original_shape[0] * 100, 2
            ),
        }


class RentabilityCalculator:
    """
    Classe pour calculer la rentabilit√© immobili√®re
    """

    @staticmethod
    def estimate_rental_yield(prix_achat: float, loyer_mensuel_estime: float) -> float:
        """
        Calcule le rendement brut estim√©

        Args:
            prix_achat: Prix d'achat du bien
            loyer_mensuel_estime: Loyer mensuel estim√©

        Returns:
            Rendement brut en pourcentage
        """
        if prix_achat <= 0 or loyer_mensuel_estime <= 0:
            return np.nan

        loyer_annuel = loyer_mensuel_estime * 12
        return (loyer_annuel / prix_achat) * 100

    @staticmethod
    def estimate_monthly_rent(surface_m2: float, loyer_m2_moyen: float) -> float:
        """
        Estime le loyer mensuel bas√© sur la surface et le loyer au m¬≤ moyen

        Args:
            surface_m2: Surface du bien en m¬≤
            loyer_m2_moyen: Loyer moyen au m¬≤ dans la zone

        Returns:
            Loyer mensuel estim√©
        """
        if surface_m2 <= 0 or loyer_m2_moyen <= 0:
            return np.nan

        return surface_m2 * loyer_m2_moyen


class GeographicAnalyzer:
    """
    Classe pour les analyses g√©ographiques
    """

    @staticmethod
    def get_top_communes(
        df: pd.DataFrame, metric: str = "prix_m2", n_top: int = 10, ascending: bool = False
    ) -> pd.DataFrame:
        """
        Obtient le top des communes selon une m√©trique

        Args:
            df: DataFrame avec les donn√©es
            metric: M√©trique √† utiliser pour le classement
            n_top: Nombre de communes √† retourner
            ascending: Ordre croissant ou d√©croissant

        Returns:
            DataFrame avec le top des communes
        """
        if metric not in df.columns:
            raise ValueError(f"La colonne {metric} n'existe pas")

        result = df.groupby("nom_commune")[metric].agg(["mean", "count"]).reset_index()

        result.columns = ["commune", f"{metric}_moyen", "nb_transactions"]

        # Filtrer les communes avec au moins 5 transactions
        result = result[result["nb_transactions"] >= 5]

        return (
            result.sort_values(f"{metric}_moyen", ascending=ascending)
            .head(n_top)
            .reset_index(drop=True)
        )

    @staticmethod
    def get_market_summary(df: pd.DataFrame, group_by: str = "nom_commune") -> pd.DataFrame:
        """
        G√©n√®re un r√©sum√© du march√© par zone g√©ographique

        Args:
            df: DataFrame avec les donn√©es DVF nettoy√©es
            group_by: Colonne de regroupement ('nom_commune', 'code_departement', etc.)

        Returns:
            DataFrame avec les statistiques par zone
        """
        if group_by not in df.columns:
            raise ValueError(f"La colonne {group_by} n'existe pas")

        summary = (
            df.groupby(group_by)
            .agg(
                {
                    "valeur_fonciere": ["count", "mean", "median"],
                    "prix_m2": ["mean", "median", "std"],
                    "surface_reelle_bati": ["mean", "median"],
                }
            )
            .round(2)
        )

        # Aplatir les colonnes multi-index
        summary.columns = ["_".join(col).strip() for col in summary.columns.values]
        summary = summary.reset_index()

        # Renommer les colonnes pour plus de clart√©
        rename_dict = {
            "valeur_fonciere_count": "nb_transactions",
            "valeur_fonciere_mean": "prix_moyen",
            "valeur_fonciere_median": "prix_median",
            "prix_m2_mean": "prix_m2_moyen",
            "prix_m2_median": "prix_m2_median",
            "prix_m2_std": "prix_m2_volatilite",
            "surface_reelle_bati_mean": "surface_moyenne",
            "surface_reelle_bati_median": "surface_mediane",
        }

        summary = summary.rename(columns=rename_dict)

        # Filtrer les zones avec au moins 5 transactions
        summary = summary[summary["nb_transactions"] >= 5]

        return summary.sort_values("nb_transactions", ascending=False)


class InvestmentAnalyzer:
    """
    Classe pour l'analyse d'investissement immobilier
    """

    @staticmethod
    @staticmethod
    def _calculate_price_score(prix_m2: float, prix_m2_moyen_zone: float) -> int:
        """Calcule le score bas√© sur le prix par rapport √† la moyenne de la zone"""
        ratio_prix = prix_m2 / prix_m2_moyen_zone
        if ratio_prix <= 0.8:
            return 5  # Tr√®s bon
        elif ratio_prix <= 0.9:
            return 4  # Bon
        elif ratio_prix <= 1.1:
            return 3  # Moyen
        elif ratio_prix <= 1.2:
            return 2  # Cher
        else:
            return 1  # Tr√®s cher

    @staticmethod
    def _calculate_liquidity_score(nb_transactions: int) -> int:
        """Calcule le score de liquidit√© bas√© sur le nombre de transactions"""
        if nb_transactions >= 50:
            return 5
        elif nb_transactions >= 20:
            return 4
        elif nb_transactions >= 10:
            return 3
        elif nb_transactions >= 5:
            return 2
        else:
            return 1

    @staticmethod
    def _calculate_size_score(surface: float) -> int:
        """Calcule le score bas√© sur la taille du bien"""
        if 50 <= surface <= 100:
            return 5  # Taille id√©ale pour location
        elif 40 <= surface <= 120:
            return 4
        elif 30 <= surface <= 140:
            return 3
        else:
            return 2

    @staticmethod
    def _calculate_yield_score(prix_m2: float, loyer_m2_estime: float = None) -> tuple:
        """Calcule le score et le rendement bas√© sur le loyer estim√©"""
        if loyer_m2_estime:
            rendement_brut = (loyer_m2_estime * 12) / prix_m2 * 100
            
            if rendement_brut >= 8:
                score = 5
            elif rendement_brut >= 6:
                score = 4
            elif rendement_brut >= 4:
                score = 3
            elif rendement_brut >= 3:
                score = 2
            else:
                score = 1
            
            return score, rendement_brut
        else:
            return 3, None  # Score neutre si pas de donn√©e

    @classmethod
    def calculate_investment_score(
        cls,
        prix_m2: float,
        surface: float,
        nb_transactions: int,
        prix_m2_moyen_zone: float,
        loyer_m2_estime: float = None,
    ) -> Dict:
        """
        Calcule un score d'investissement bas√© sur plusieurs crit√®res

        Args:
            prix_m2: Prix au m¬≤ du bien
            surface: Surface du bien
            nb_transactions: Nombre de transactions dans la zone
            prix_m2_moyen_zone: Prix moyen au m¬≤ dans la zone
            loyer_m2_estime: Loyer estim√© au m¬≤ (optionnel)

        Returns:
            Dictionnaire avec les scores et m√©triques
        """
        scores = {}

        # Calcul des scores individuels
        scores["score_prix"] = cls._calculate_price_score(prix_m2, prix_m2_moyen_zone)
        scores["score_liquidite"] = cls._calculate_liquidity_score(nb_transactions)
        scores["score_taille"] = cls._calculate_size_score(surface)
        
        score_rendement, rendement_brut = cls._calculate_yield_score(prix_m2, loyer_m2_estime)
        scores["score_rendement"] = score_rendement
        
        if rendement_brut is not None:
            scores["rendement_brut_estime"] = rendement_brut

        # Score global (moyenne pond√©r√©e)
        poids = {
            "score_prix": 0.3,
            "score_liquidite": 0.2,
            "score_taille": 0.2,
            "score_rendement": 0.3,
        }

        score_global = sum(scores[k] * poids[k] for k in poids.keys())
        scores["score_global"] = round(score_global, 2)

        # Classification
        if score_global >= 4.5:
            scores["classification"] = "Excellent"
        elif score_global >= 3.5:
            scores["classification"] = "Tr√®s bon"
        elif score_global >= 2.5:
            scores["classification"] = "Bon"
        elif score_global >= 1.5:
            scores["classification"] = "Moyen"
        else:
            scores["classification"] = "Faible"

        return scores

    @staticmethod
    def find_investment_opportunities(
        df: pd.DataFrame,
        max_prix_m2: float = None,
        min_surface: float = 30,
        max_surface: float = 120,
        min_transactions_zone: int = 10,
    ) -> pd.DataFrame:
        """
        Identifie les opportunit√©s d'investissement dans le dataset

        Args:
            df: DataFrame avec les donn√©es DVF nettoy√©es
            max_prix_m2: Prix maximum au m¬≤ accept√©
            min_surface: Surface minimale
            max_surface: Surface maximale
            min_transactions_zone: Nombre minimum de transactions dans la zone

        Returns:
            DataFrame avec les opportunit√©s tri√©es par score
        """
        # Filtrage de base
        opportunities = df.copy()

        if min_surface:
            opportunities = opportunities[opportunities["surface_reelle_bati"] >= min_surface]
        if max_surface:
            opportunities = opportunities[opportunities["surface_reelle_bati"] <= max_surface]
        if max_prix_m2:
            opportunities = opportunities[opportunities["prix_m2"] <= max_prix_m2]

        # Calcul des statistiques par commune
        commune_stats = (
            opportunities.groupby("nom_commune")
            .agg({"prix_m2": "mean", "valeur_fonciere": "count"})
            .rename(
                columns={
                    "prix_m2": "prix_m2_moyen_commune",
                    "valeur_fonciere": "nb_transactions_commune",
                }
            )
        )

        # Filtrer les communes avec assez de transactions
        commune_stats = commune_stats[
            commune_stats["nb_transactions_commune"] >= min_transactions_zone
        ]

        # Joindre les statistiques
        opportunities = opportunities.merge(
            commune_stats, left_on="nom_commune", right_index=True, how="inner"
        )

        # Calcul des scores d'investissement
        scores_list = []
        for _, row in opportunities.iterrows():
            score = InvestmentAnalyzer.calculate_investment_score(
                prix_m2=row["prix_m2"],
                surface=row["surface_reelle_bati"],
                nb_transactions=row["nb_transactions_commune"],
                prix_m2_moyen_zone=row["prix_m2_moyen_commune"],
            )
            scores_list.append(score)

        # Ajouter les scores au DataFrame
        scores_df = pd.DataFrame(scores_list)
        opportunities = pd.concat([opportunities.reset_index(drop=True), scores_df], axis=1)

        # Trier par score global d√©croissant
        opportunities = opportunities.sort_values("score_global", ascending=False)

        return opportunities[
            [
                "nom_commune",
                "valeur_fonciere",
                "surface_reelle_bati",
                "prix_m2",
                "prix_m2_moyen_commune",
                "score_global",
                "classification",
                "score_prix",
                "score_liquidite",
                "score_taille",
                "score_rendement",
            ]
        ]


def load_dvf_data(file_path: str) -> pd.DataFrame:
    """
    Charge les donn√©es DVF depuis un fichier CSV

    Args:
        file_path: Chemin vers le fichier CSV

    Returns:
        DataFrame avec les donn√©es DVF
    """
    try:
        # Essayer diff√©rents encodages pour les fichiers DVF fran√ßais
        encodings = ["utf-8", "iso-8859-1", "windows-1252", "cp1252"]

        for encoding in encodings:
            try:
                # DVF utilise g√©n√©ralement le point-virgule comme s√©parateur
                df = pd.read_csv(file_path, low_memory=False, encoding=encoding, sep=";")
                print(
                    f"‚úÖ Donn√©es charg√©es avec encodage {encoding} : "
                    f"{df.shape[0]} lignes, {df.shape[1]} colonnes"
                )

                # Conversion automatique de la date si pr√©sente
                if "date_mutation" in df.columns:
                    df["date_mutation"] = pd.to_datetime(df["date_mutation"])
                    print(
                        f"üìÖ P√©riode couverte : {df['date_mutation'].min()} "
                        f"√† {df['date_mutation'].max()}"
                    )

                return df
            except UnicodeDecodeError:
                continue

        # Si aucun encodage ne fonctionne, essayer avec errors='ignore'
        df = pd.read_csv(file_path, low_memory=False, encoding="utf-8", errors="ignore", sep=";")
        print(
            f"‚úÖ Donn√©es charg√©es avec encodage UTF-8 (errors='ignore') : {df.shape[0]} lignes, {df.shape[1]} colonnes"
        )

        if "date_mutation" in df.columns:
            df["date_mutation"] = pd.to_datetime(df["date_mutation"])
            print(
                f"üìÖ P√©riode couverte : {df['date_mutation'].min()} √† {df['date_mutation'].max()}"
            )

        return df

    except FileNotFoundError:
        print(f"‚ùå Fichier non trouv√© : {file_path}")
        raise
    except Exception as e:
        print(f"‚ùå Erreur lors du chargement : {e}")
        raise


class StatisticalAnalyzer:
    """
    Classe pour les analyses statistiques avanc√©es des donn√©es DVF (T015-T019)
    """

    @staticmethod
    def comprehensive_descriptive_stats(df: pd.DataFrame, variables: List[str] = None) -> Dict:
        """
        T015 - Statistiques descriptives compl√®tes pour les variables principales

        Args:
            df: DataFrame avec les donn√©es
            variables: Liste des variables √† analyser (par d√©faut: prix, surface, pi√®ces)

        Returns:
            Dictionnaire avec les statistiques compl√®tes
        """
        if variables is None:
            variables = ["valeur_fonciere", "prix_m2", "surface_reelle_bati"]
            if "nombre_pieces_principales" in df.columns:
                variables.append("nombre_pieces_principales")

        stats_dict = {}

        for var in variables:
            if var in df.columns:
                data = df[var].dropna()

                if len(data) > 0:
                    stats_dict[var] = {
                        "count": len(data),
                        "mean": float(data.mean()),
                        "median": float(data.median()),
                        "std": float(data.std()),
                        "min": float(data.min()),
                        "max": float(data.max()),
                        "q1": float(data.quantile(0.25)),
                        "q3": float(data.quantile(0.75)),
                        "skewness": float(stats.skew(data)),
                        "kurtosis": float(stats.kurtosis(data)),
                        "cv": float(data.std() / data.mean() * 100) if data.mean() != 0 else np.nan,
                    }

        return stats_dict

    @staticmethod
    def geographical_price_analysis(
        df: pd.DataFrame, by_commune: bool = True, by_department: bool = True
    ) -> Dict:
        """
        T016 - Analyse des prix par commune et d√©partement

        Args:
            df: DataFrame avec les donn√©es
            by_commune: Analyser par commune
            by_department: Analyser par d√©partement

        Returns:
            Dictionnaire avec les analyses g√©ographiques
        """
        results = {}

        if by_department and "code_departement" in df.columns:
            dept_analysis = (
                df.groupby("code_departement")
                .agg(
                    {
                        "prix_m2": ["mean", "median", "std", "count"],
                        "valeur_fonciere": ["mean", "median"],
                        "surface_reelle_bati": "mean",
                    }
                )
                .round(2)
            )

            dept_analysis.columns = ["_".join(col).strip() for col in dept_analysis.columns]
            dept_analysis = dept_analysis.reset_index()
            dept_analysis = dept_analysis[
                dept_analysis["prix_m2_count"] >= 10
            ]  # Min 10 transactions

            results["departements"] = dept_analysis.sort_values("prix_m2_mean", ascending=False)

        if by_commune and "nom_commune" in df.columns:
            commune_analysis = (
                df.groupby(["nom_commune", "code_departement"])
                .agg(
                    {
                        "prix_m2": ["mean", "median", "count"],
                        "valeur_fonciere": "mean",
                        "surface_reelle_bati": "mean",
                    }
                )
                .round(2)
            )

            commune_analysis.columns = ["_".join(col).strip() for col in commune_analysis.columns]
            commune_analysis = commune_analysis.reset_index()
            commune_analysis = commune_analysis[
                commune_analysis["prix_m2_count"] >= 5
            ]  # Min 5 transactions

            results["communes"] = commune_analysis.sort_values("prix_m2_mean", ascending=False)

        return results

    @staticmethod
    def property_type_analysis(df: pd.DataFrame) -> Dict:
        """
        T017 - Analyse d√©taill√©e par type de propri√©t√©

        Args:
            df: DataFrame avec les donn√©es

        Returns:
            Dictionnaire avec l'analyse par type de bien
        """
        if "type_local" not in df.columns:
            return {"error": "Colonne type_local non disponible"}

        results = {}

        # Analyse globale par type
        type_analysis = (
            df.groupby("type_local")
            .agg(
                {
                    "prix_m2": ["mean", "median", "std", "count"],
                    "valeur_fonciere": ["mean", "median", "std"],
                    "surface_reelle_bati": ["mean", "median", "std"],
                }
            )
            .round(2)
        )

        type_analysis.columns = ["_".join(col).strip() for col in type_analysis.columns]
        type_analysis = type_analysis.reset_index()

        results["global_analysis"] = type_analysis

        # Analyse par type et d√©partement
        type_dept_analysis = {}
        for type_bien in df["type_local"].value_counts().head(3).index:
            df_type = df[df["type_local"] == type_bien]
            dept_type = (
                df_type.groupby("code_departement")
                .agg({"prix_m2": ["mean", "count"], "surface_reelle_bati": "mean"})
                .round(2)
            )

            dept_type.columns = ["_".join(col).strip() for col in dept_type.columns]
            dept_type = dept_type.reset_index()
            dept_type = dept_type[dept_type["prix_m2_count"] >= 5]

            type_dept_analysis[type_bien] = dept_type.sort_values("prix_m2_mean", ascending=False)

        results["by_department"] = type_dept_analysis

        return results

    @staticmethod
    def temporal_evolution_analysis(df: pd.DataFrame) -> Dict:
        """
        T018 - Analyse de l'√©volution temporelle

        Args:
            df: DataFrame avec les donn√©es (doit contenir date_mutation)

        Returns:
            Dictionnaire avec les analyses temporelles
        """
        if "date_mutation" not in df.columns:
            return {"error": "Colonne date_mutation non disponible"}

        results = {}

        # Analyse annuelle
        yearly_analysis = (
            df.groupby("annee_mutation")
            .agg(
                {
                    "prix_m2": ["mean", "median", "count"],
                    "valeur_fonciere": ["mean", "sum"],
                    "surface_reelle_bati": "mean",
                }
            )
            .round(2)
        )

        yearly_analysis.columns = ["_".join(col).strip() for col in yearly_analysis.columns]
        yearly_analysis = yearly_analysis.reset_index()

        # Calcul des taux de croissance
        yearly_analysis["croissance_prix"] = yearly_analysis["prix_m2_mean"].pct_change() * 100
        yearly_analysis["croissance_volume"] = yearly_analysis["prix_m2_count"].pct_change() * 100

        results["yearly"] = yearly_analysis

        # Analyse mensuelle
        monthly_analysis = (
            df.groupby(["annee_mutation", "mois_mutation"])
            .agg({"prix_m2": ["mean", "count"], "valeur_fonciere": "mean"})
            .round(2)
        )

        monthly_analysis.columns = ["_".join(col).strip() for col in monthly_analysis.columns]
        monthly_analysis = monthly_analysis.reset_index()

        results["monthly"] = monthly_analysis

        # Analyse de saisonnalit√©
        seasonal_analysis = (
            df.groupby("mois_mutation")
            .agg({"prix_m2": ["mean", "count"], "valeur_fonciere": "mean"})
            .round(2)
        )

        seasonal_analysis.columns = ["_".join(col).strip() for col in seasonal_analysis.columns]
        seasonal_analysis = seasonal_analysis.reset_index()

        # Calcul des variations par rapport √† la moyenne annuelle
        prix_moyen_annuel = df["prix_m2"].mean()
        seasonal_analysis["variation_vs_moyenne"] = (
            seasonal_analysis["prix_m2_mean"] / prix_moyen_annuel - 1
        ) * 100

        results["seasonal"] = seasonal_analysis

        return results

    @staticmethod
    def outlier_detection(
        df: pd.DataFrame, variables: List[str] = None, method: str = "iqr"
    ) -> Dict:
        """
        T019 - D√©tection d'outliers et d'anomalies

        Args:
            df: DataFrame avec les donn√©es
            variables: Variables √† analyser pour les outliers
            method: M√©thode de d√©tection ('iqr', 'zscore', 'modified_zscore')

        Returns:
            Dictionnaire avec les outliers d√©tect√©s
        """
        if variables is None:
            variables = ["prix_m2", "surface_reelle_bati", "valeur_fonciere"]

        results = {}

        for var in variables:
            if var not in df.columns:
                continue

            data = df[var].dropna()
            outliers_info = {}

            if method == "iqr":
                Q1 = data.quantile(0.25)
                Q3 = data.quantile(0.75)
                IQR = Q3 - Q1
                lower_bound = Q1 - 1.5 * IQR
                upper_bound = Q3 + 1.5 * IQR

                outliers_mask = (data < lower_bound) | (data > upper_bound)

                outliers_info = {
                    "method": "IQR",
                    "q1": float(Q1),
                    "q3": float(Q3),
                    "iqr": float(IQR),
                    "lower_bound": float(lower_bound),
                    "upper_bound": float(upper_bound),
                    "outliers_count": int(outliers_mask.sum()),
                    "outliers_percentage": float(outliers_mask.sum() / len(data) * 100),
                    "outliers_indices": outliers_mask[outliers_mask].index.tolist(),
                }

            elif method == "zscore":
                z_scores = np.abs(stats.zscore(data))
                threshold = 3
                outliers_mask = z_scores > threshold

                outliers_info = {
                    "method": "Z-Score",
                    "threshold": threshold,
                    "outliers_count": int(outliers_mask.sum()),
                    "outliers_percentage": float(outliers_mask.sum() / len(data) * 100),
                    "outliers_indices": data.index[outliers_mask].tolist(),
                }

            results[var] = outliers_info

        return results

    @staticmethod
    def market_anomalies_detection(df: pd.DataFrame) -> Dict:
        """
        T019 - D√©tection d'anomalies sp√©cifiques au march√© immobilier

        Args:
            df: DataFrame avec les donn√©es

        Returns:
            Dictionnaire avec les anomalies d√©tect√©es
        """
        results = {}

        # Anomalies temporelles
        if "date_mutation" in df.columns:
            daily_volumes = df.groupby("date_mutation").size()
            high_volume_threshold = daily_volumes.quantile(0.95)
            high_volume_days = daily_volumes[daily_volumes > high_volume_threshold]

            results["temporal_anomalies"] = {
                "high_volume_days": len(high_volume_days),
                "threshold": float(high_volume_threshold),
                "dates": high_volume_days.index.strftime("%Y-%m-%d").tolist(),
                "volumes": high_volume_days.values.tolist(),
            }

        # Anomalies g√©ographiques (communes avec √©carts importants vs d√©partement)
        if all(col in df.columns for col in ["nom_commune", "code_departement", "prix_m2"]):
            dept_avg_prices = df.groupby("code_departement")["prix_m2"].mean()

            commune_vs_dept = (
                df.groupby(["nom_commune", "code_departement"])
                .agg({"prix_m2": ["mean", "count"]})
                .round(2)
            )

            commune_vs_dept.columns = ["prix_m2_commune", "nb_transactions"]
            commune_vs_dept = commune_vs_dept.reset_index()
            commune_vs_dept = commune_vs_dept[commune_vs_dept["nb_transactions"] >= 5]

            commune_vs_dept["prix_m2_dept"] = commune_vs_dept["code_departement"].map(
                dept_avg_prices
            )
            commune_vs_dept["ecart_vs_dept"] = (
                commune_vs_dept["prix_m2_commune"] / commune_vs_dept["prix_m2_dept"] - 1
            ) * 100

            # Communes avec surprime/d√©cote importante
            surprimes = commune_vs_dept[commune_vs_dept["ecart_vs_dept"] > 50]
            decotes = commune_vs_dept[commune_vs_dept["ecart_vs_dept"] < -30]

            results["geographical_anomalies"] = {
                "surprimes_importantes": {
                    "count": len(surprimes),
                    "communes": surprimes.nlargest(10, "ecart_vs_dept")[
                        [
                            "nom_commune",
                            "code_departement", 
                            "ecart_vs_dept",
                            "prix_m2_commune",
                        ]
                    ].to_dict("records"),
                },
                "decotes_importantes": {
                    "count": len(decotes),
                    "communes": decotes.nsmallest(10, "ecart_vs_dept")[
                        ["nom_commune", "code_departement", "ecart_vs_dept", "prix_m2_commune"]
                    ].to_dict("records"),
                },
            }

        return results

    @staticmethod
    def investment_market_analysis(df: pd.DataFrame, target_yield: float = 4.0) -> Dict:
        """
        Analyse compl√®te pour l'investissement immobilier

        Args:
            df: DataFrame avec les donn√©es DVF
            target_yield: Rendement cible en pourcentage

        Returns:
            Dictionnaire avec l'analyse d'investissement
        """
        results = {}

        # Segments par surface pour l'investissement locatif
        df_copy = df.copy()
        df_copy["segment_surface"] = pd.cut(
            df_copy["surface_reelle_bati"],
            bins=[0, 30, 50, 70, 100, 150, float("inf")],
            labels=["<30m¬≤", "30-50m¬≤", "50-70m¬≤", "70-100m¬≤", "100-150m¬≤", ">150m¬≤"],
        )

        segment_analysis = (
            df_copy.groupby("segment_surface")
            .agg(
                {
                    "prix_m2": ["mean", "count"],
                    "valeur_fonciere": "mean",
                    "surface_reelle_bati": "mean",
                }
            )
            .round(2)
        )

        segment_analysis.columns = ["_".join(col).strip() for col in segment_analysis.columns]
        segment_analysis = segment_analysis.reset_index()

        results["surface_segments"] = segment_analysis

        # Estimation de rentabilit√© par type et zone
        if "type_local" in df.columns:
            # Hypoth√®ses de rendement par type (taux mensuel)
            rental_rates = {
                "Appartement": 0.009,  # 0.9% par mois
                "Maison": 0.008,  # 0.8% par mois
                "Local industriel. commercial ou assimil√©": 0.007,  # 0.7% par mois
            }

            yield_analysis = []

            for type_bien in df["type_local"].value_counts().head(3).index:
                df_type = df[df["type_local"] == type_bien]
                monthly_rate = rental_rates.get(type_bien, 0.008)

                type_stats = {
                    "type_bien": type_bien,
                    "prix_achat_moyen": float(df_type["valeur_fonciere"].mean()),
                    "prix_m2_moyen": float(df_type["prix_m2"].mean()),
                    "surface_moyenne": float(df_type["surface_reelle_bati"].mean()),
                    "taux_mensuel_estime": monthly_rate,
                    "loyer_mensuel_estime": float(df_type["valeur_fonciere"].mean() * monthly_rate),
                    "rendement_brut_estime": float(monthly_rate * 12 * 100),
                    "nb_transactions": len(df_type),
                }

                yield_analysis.append(type_stats)

            results["yield_analysis"] = yield_analysis

        return results


class InvestmentRecommendationEngine:
    """
    Moteur de recommandations d'investissement immobilier (T028-T034)
    """

    def __init__(self, dvf_data: pd.DataFrame, rental_data: pd.DataFrame = None):
        """
        Initialise le moteur de recommandations

        Args:
            dvf_data: DataFrame avec les donn√©es DVF nettoy√©es
            rental_data: DataFrame avec les donn√©es de loyer par d√©partement
        """
        self.dvf_data = dvf_data.copy()
        self.rental_data = rental_data.copy() if rental_data is not None else None
        self._prepare_data()

    def _prepare_data(self):
        """Pr√©pare les donn√©es pour les calculs"""
        # Conversion des codes d√©partement
        if "code_departement" in self.dvf_data.columns:
            self.dvf_data["code_departement"] = (
                self.dvf_data["code_departement"].astype(str).str.replace(".0", "")
            )

        # Calcul du mois de mutation
        if "date_mutation" in self.dvf_data.columns:
            self.dvf_data["mois_mutation"] = self.dvf_data["date_mutation"].dt.month

    def integrate_rental_data(self) -> pd.DataFrame:
        """
        T028 - Int√®gre les donn√©es de loyer avec les donn√©es DVF

        Returns:
            DataFrame int√©gr√© avec estimations de loyer
        """
        if self.rental_data is None:
            print("‚ö†Ô∏è Pas de donn√©es de loyer disponibles - cr√©ation de donn√©es simul√©es")
            return self._create_simulated_rental_data()

        # Pr√©paration des codes d√©partement dans les donn√©es de loyer
        if "D√©partement" in self.rental_data.columns:
            self.rental_data["code_departement"] = (
                self.rental_data["D√©partement"].astype(str).str.zfill(2)
            )

        # Fusion des donn√©es
        integrated_data = self.dvf_data.merge(
            self.rental_data[["code_departement", "Loyer m√©dian", "Loyer/m¬≤ m√©dian"]],
            on="code_departement",
            how="left",
        )

        # Calcul des estimations de loyer mensuel
        integrated_data["loyer_mensuel_estime"] = (
            integrated_data["surface_reelle_bati"] * integrated_data["Loyer/m¬≤ m√©dian"]
        )

        return integrated_data

    def _create_simulated_rental_data(self) -> pd.DataFrame:
        """Cr√©e des donn√©es de loyer simul√©es bas√©es sur les prix DVF"""
        dvf_with_rental = self.dvf_data.copy()

        # Estimation bas√©e sur un ratio prix/loyer typique (20-25 ans)
        ratio_prix_loyer = 22  # 22 ann√©es de loyer = prix d'achat

        dvf_with_rental["loyer_mensuel_estime"] = dvf_with_rental["valeur_fonciere"] / (
            ratio_prix_loyer * 12
        )

        dvf_with_rental["loyer_m2_estime"] = (
            dvf_with_rental["loyer_mensuel_estime"] / dvf_with_rental["surface_reelle_bati"]
        )

        return dvf_with_rental

    def calculate_rental_yields(self, data: pd.DataFrame) -> pd.DataFrame:
        """
        T029 - Calcule les rendements locatifs

        Args:
            data: DataFrame avec les donn√©es int√©gr√©es

        Returns:
            DataFrame avec les rendements calcul√©s
        """
        data_with_yields = data.copy()

        # Rendement brut
        data_with_yields["rendement_brut"] = (
            (data_with_yields["loyer_mensuel_estime"] * 12)
            / data_with_yields["valeur_fonciere"]
            * 100
        )

        # Rendement net estim√© (brut - 25% de charges et imp√¥ts)
        data_with_yields["rendement_net_estime"] = data_with_yields["rendement_brut"] * 0.75

        # Classification des rendements
        conditions = [
            data_with_yields["rendement_brut"] >= 8,
            data_with_yields["rendement_brut"] >= 6,
            data_with_yields["rendement_brut"] >= 4,
            data_with_yields["rendement_brut"] >= 3,
        ]

        choices = ["Excellent", "Tr√®s bon", "Bon", "Moyen"]

        data_with_yields["classe_rendement"] = np.select(conditions, choices, default="Faible")

        return data_with_yields

    def calculate_multi_criteria_score(self, data: pd.DataFrame) -> pd.DataFrame:
        """
        T030 - Calcule un score multi-crit√®res d'investissement

        Args:
            data: DataFrame avec les donn√©es et rendements

        Returns:
            DataFrame avec les scores multi-crit√®res
        """
        data_with_scores = data.copy()

        # Calcul des statistiques par commune pour les scores relatifs
        commune_stats = (
            data.groupby("nom_commune")
            .agg({"prix_m2": "mean", "valeur_fonciere": "count"})
            .rename(
                columns={
                    "prix_m2": "prix_m2_moyen_commune",
                    "valeur_fonciere": "nb_transactions_commune",
                }
            )
        )

        # Ajouter le rendement moyen par commune si disponible
        if "rendement_brut" in data.columns:
            commune_stats["rendement_moyen_commune"] = data.groupby("nom_commune")[
                "rendement_brut"
            ].mean()

        data_with_scores = data_with_scores.merge(
            commune_stats, left_on="nom_commune", right_index=True, how="left"
        )

        # Score prix (0-10) - plus c'est en dessous de la moyenne, mieux c'est
        data_with_scores["ratio_prix"] = (
            data_with_scores["prix_m2"] / data_with_scores["prix_m2_moyen_commune"]
        )
        data_with_scores["score_prix"] = np.where(
            data_with_scores["ratio_prix"] <= 0.8,
            10,
            np.where(
                data_with_scores["ratio_prix"] <= 0.9,
                8,
                np.where(
                    data_with_scores["ratio_prix"] <= 1.0,
                    6,
                    np.where(
                        data_with_scores["ratio_prix"] <= 1.1,
                        4,
                        np.where(data_with_scores["ratio_prix"] <= 1.2, 2, 0),
                    ),
                ),
            ),
        )

        # Score liquidit√© (0-10) - bas√© sur le nombre de transactions
        data_with_scores["score_liquidite"] = np.where(
            data_with_scores["nb_transactions_commune"] >= 100,
            10,
            np.where(
                data_with_scores["nb_transactions_commune"] >= 50,
                8,
                np.where(
                    data_with_scores["nb_transactions_commune"] >= 20,
                    6,
                    np.where(
                        data_with_scores["nb_transactions_commune"] >= 10,
                        4,
                        np.where(data_with_scores["nb_transactions_commune"] >= 5, 2, 0),
                    ),
                ),
            ),
        )

        # Score surface (0-10) - privil√©gier les surfaces moyennes
        data_with_scores["score_surface"] = np.where(
            (data_with_scores["surface_reelle_bati"] >= 50)
            & (data_with_scores["surface_reelle_bati"] <= 80),
            10,
            np.where(
                (data_with_scores["surface_reelle_bati"] >= 40)
                & (data_with_scores["surface_reelle_bati"] <= 100),
                8,
                np.where(
                    (data_with_scores["surface_reelle_bati"] >= 30)
                    & (data_with_scores["surface_reelle_bati"] <= 120),
                    6,
                    np.where(
                        (data_with_scores["surface_reelle_bati"] >= 25)
                        & (data_with_scores["surface_reelle_bati"] <= 150),
                        4,
                        2,
                    ),
                ),
            ),
        )

        # Score rendement (0-10)
        data_with_scores["score_rendement"] = np.where(
            data_with_scores["rendement_brut"] >= 8,
            10,
            np.where(
                data_with_scores["rendement_brut"] >= 6,
                8,
                np.where(
                    data_with_scores["rendement_brut"] >= 4,
                    6,
                    np.where(
                        data_with_scores["rendement_brut"] >= 3,
                        4,
                        np.where(data_with_scores["rendement_brut"] >= 2, 2, 0),
                    ),
                ),
            ),
        )

        # Score global pond√©r√©
        weights = {
            "score_prix": 0.25,
            "score_liquidite": 0.20,
            "score_surface": 0.15,
            "score_rendement": 0.40,
        }

        data_with_scores["score_global"] = (
            data_with_scores["score_prix"] * weights["score_prix"]
            + data_with_scores["score_liquidite"] * weights["score_liquidite"]
            + data_with_scores["score_surface"] * weights["score_surface"]
            + data_with_scores["score_rendement"] * weights["score_rendement"]
        )

        # Classification finale
        data_with_scores["classe_investissement"] = np.where(
            data_with_scores["score_global"] >= 8,
            "Excellent",
            np.where(
                data_with_scores["score_global"] >= 6,
                "Tr√®s bon",
                np.where(
                    data_with_scores["score_global"] >= 4,
                    "Bon",
                    np.where(data_with_scores["score_global"] >= 2, "Moyen", "Faible"),
                ),
            ),
        )

        return data_with_scores

    def identify_attractive_zones(
        self, data: pd.DataFrame, min_transactions: int = 10
    ) -> pd.DataFrame:
        """
        T031 - Identifie les zones attractives pour l'investissement

        Args:
            data: DataFrame avec les scores calcul√©s
            min_transactions: Nombre minimum de transactions par zone

        Returns:
            DataFrame avec les zones attractives
        """
        # Agr√©gation par commune
        agg_dict = {
            "score_global": "mean",
            "prix_m2": "mean",
            "valeur_fonciere": ["mean", "count"],
            "surface_reelle_bati": "mean",
            "score_prix": "mean",
            "score_liquidite": "mean",
        }

        # Ajouter le rendement et score rendement s'ils existent
        if "rendement_brut" in data.columns:
            agg_dict["rendement_brut"] = "mean"
        if "score_rendement" in data.columns:
            agg_dict["score_rendement"] = "mean"

        zones_analysis = data.groupby(["nom_commune", "code_departement"]).agg(agg_dict).round(2)

        # Debug: print columns before flattening
        # print("Colonnes avant aplatissement:", zones_analysis.columns.tolist())

        # Aplatir les colonnes multi-index plus soigneusement
        new_columns = []
        for col in zones_analysis.columns.values:
            if isinstance(col, tuple):
                if len(col) > 1 and col[1] != "":
                    new_columns.append("_".join(col).strip())
                else:
                    new_columns.append(col[0])
            else:
                new_columns.append(col)

        zones_analysis.columns = new_columns
        zones_analysis = zones_analysis.reset_index()

        # Debug: print columns after flattening
        # print("Colonnes apr√®s aplatissement:", zones_analysis.columns.tolist())

        # Renommer les colonnes pour plus de clart√©
        zones_analysis = zones_analysis.rename(
            columns={
                "valeur_fonciere_mean": "prix_moyen",
                "valeur_fonciere_count": "nb_transactions",
                "score_global_mean": "score_global",
                "prix_m2_mean": "prix_m2",
                "surface_reelle_bati_mean": "surface_reelle_bati",
                "score_prix_mean": "score_prix",
                "score_liquidite_mean": "score_liquidite",
                "rendement_brut_mean": "rendement_brut",
                "score_rendement_mean": "score_rendement",
            }
        )

        # Filtrer par nombre minimum de transactions
        zones_attractives = zones_analysis[zones_analysis["nb_transactions"] >= min_transactions]

        # Ajouter des indicateurs de performance
        if (
            "rendement_brut" in zones_attractives.columns
            and "score_prix" in zones_attractives.columns
        ):
            zones_attractives["rentabilite_prix"] = (
                zones_attractives["rendement_brut"] * zones_attractives["score_prix"] / 100
            )

        # Classement par score global
        zones_attractives = zones_attractives.sort_values("score_global", ascending=False)

        # Cat√©gorisation des zones
        zones_attractives["categorie_zone"] = np.where(
            zones_attractives["score_global"] >= 7,
            "Zone Premium",
            np.where(
                zones_attractives["score_global"] >= 5,
                "Zone Attractive",
                np.where(zones_attractives["score_global"] >= 3, "Zone Correct", "Zone √† √âviter"),
            ),
        )

        return zones_attractives

    def _filter_zones_by_criteria(
        self,
        zones_data: pd.DataFrame,
        budget_max: float,
        surface_min: float,
        surface_max: float,
        rendement_min: float,
    ) -> pd.DataFrame:
        """Filtre les zones selon les crit√®res de l'investisseur"""
        filter_conditions = []

        if "prix_moyen" in zones_data.columns:
            filter_conditions.append(zones_data["prix_moyen"] <= budget_max)
        if "surface_reelle_bati" in zones_data.columns:
            filter_conditions.append(zones_data["surface_reelle_bati"] >= surface_min)
            filter_conditions.append(zones_data["surface_reelle_bati"] <= surface_max)
        if "rendement_brut" in zones_data.columns:
            filter_conditions.append(zones_data["rendement_brut"] >= rendement_min)

        if filter_conditions:
            combined_filter = filter_conditions[0]
            for condition in filter_conditions[1:]:
                combined_filter = combined_filter & condition
            return zones_data[combined_filter].copy()
        else:
            return zones_data.copy()

    def _get_top_recommendations(self, filtered_zones: pd.DataFrame) -> list:
        """Obtient les 5 meilleures recommandations"""
        top_recommendations = filtered_zones.head(5)
        
        available_cols = ["nom_commune", "code_departement"]
        optional_cols = [
            "score_global",
            "rendement_brut",
            "prix_moyen",
            "prix_m2",
            "categorie_zone",
        ]

        for col in optional_cols:
            if col in top_recommendations.columns:
                available_cols.append(col)

        return top_recommendations[available_cols].to_dict("records")

    def _get_strategies_recommendations(self, filtered_zones: pd.DataFrame) -> dict:
        """G√©n√®re les recommandations par strat√©gie"""
        strategies = {}

        if "rendement_brut" in filtered_zones.columns:
            strategies["rendement_max"] = filtered_zones.nlargest(3, "rendement_brut")
        if "score_prix" in filtered_zones.columns:
            strategies["prix_attractif"] = filtered_zones.nlargest(3, "score_prix")
        if "score_global" in filtered_zones.columns:
            strategies["equilibre"] = filtered_zones.nlargest(3, "score_global")

        strategy_recommendations = {}
        for strategy_name, strategy_data in strategies.items():
            strategy_cols = ["nom_commune", "code_departement"]
            for col in ["rendement_brut", "prix_moyen", "score_global"]:
                if col in strategy_data.columns:
                    strategy_cols.append(col)

            strategy_recommendations[f"strategie_{strategy_name}"] = strategy_data[
                strategy_cols
            ].to_dict("records")

        return strategy_recommendations

    def _analyze_departments(self, filtered_zones: pd.DataFrame) -> dict:
        """Analyse les zones par d√©partement"""
        dept_analysis = (
            filtered_zones.groupby("code_departement")
            .agg(
                {
                    "score_global": "mean",
                    "rendement_brut": "mean",
                    "prix_moyen": "mean",
                    "nom_commune": "count",
                }
            )
            .rename(columns={"nom_commune": "nb_communes_attractives"})
        )

        return dept_analysis.sort_values("score_global", ascending=False).to_dict("index")

    def _calculate_portfolio_stats(
        self, filtered_zones: pd.DataFrame, budget_max: float
    ) -> dict:
        """Calcule les statistiques du portefeuille recommand√©"""
        portfolio_stats = {"nb_zones_eligibles": len(filtered_zones)}

        if "rendement_brut" in filtered_zones.columns:
            portfolio_stats["rendement_moyen_estime"] = float(
                filtered_zones["rendement_brut"].mean()
            )
        if "prix_moyen" in filtered_zones.columns:
            portfolio_stats["prix_moyen_zone"] = float(filtered_zones["prix_moyen"].mean())
            min_ratio = filtered_zones["prix_moyen"].min() / budget_max * 100
            max_ratio = filtered_zones["prix_moyen"].max() / budget_max * 100
            portfolio_stats["budget_utilisation"] = f"{min_ratio:.1f}% - {max_ratio:.1f}%"
        if "score_global" in filtered_zones.columns:
            portfolio_stats["score_global_moyen"] = float(
                filtered_zones["score_global"].mean()
            )

        return portfolio_stats

    def generate_personalized_recommendations(
        self,
        zones_data: pd.DataFrame,
        budget_max: float,
        surface_min: float = 30,
        surface_max: float = 120,
        rendement_min: float = 4.0,
    ) -> Dict:
        """
        T032 - G√©n√®re des recommandations personnalis√©es

        Args:
            zones_data: DataFrame avec les zones analys√©es
            budget_max: Budget maximum de l'investisseur
            surface_min: Surface minimale souhait√©e
            surface_max: Surface maximale souhait√©e
            rendement_min: Rendement minimum souhait√©

        Returns:
            Dictionnaire avec les recommandations personnalis√©es
        """
        recommendations = {}

        # Filtrage selon les crit√®res
        filtered_zones = self._filter_zones_by_criteria(
            zones_data, budget_max, surface_min, surface_max, rendement_min
        )

        if len(filtered_zones) == 0:
            recommendations["message"] = (
                "Aucune zone ne correspond √† vos crit√®res. "
                "Consid√©rez ajuster votre budget ou vos exigences."
            )
            return recommendations

        # G√©n√©ration des recommandations
        recommendations["top_5_global"] = self._get_top_recommendations(filtered_zones)
        recommendations.update(self._get_strategies_recommendations(filtered_zones))
        recommendations["analyse_departements"] = self._analyze_departments(filtered_zones)
        recommendations["statistiques_portefeuille"] = self._calculate_portfolio_stats(
            filtered_zones, budget_max
        )

        return recommendations

    def create_executive_summary(self, recommendations: Dict, zones_data: pd.DataFrame) -> Dict:
        """
        T033 - Cr√©e un r√©sum√© ex√©cutif des recommandations

        Args:
            recommendations: Dictionnaire des recommandations
            zones_data: DataFrame avec toutes les zones analys√©es

        Returns:
            Dictionnaire avec le r√©sum√© ex√©cutif
        """
        summary = {}

        # Vue d'ensemble du march√©
        market_overview = {
            "total_zones_analysees": len(zones_data),
            "zones_premium": len(zones_data[zones_data["categorie_zone"] == "Zone Premium"]),
            "zones_attractives": len(zones_data[zones_data["categorie_zone"] == "Zone Attractive"]),
            "rendement_moyen_marche": float(zones_data["rendement_brut"].mean()),
            "prix_m2_moyen_marche": float(zones_data["prix_m2"].mean()),
        }

        summary["vue_ensemble_marche"] = market_overview

        # Opportunit√©s principales
        if "top_5_global" in recommendations:
            top_opportunity = recommendations["top_5_global"][0]

            principales_opportunites = {
                "meilleure_opportunite": {
                    "commune": top_opportunity["nom_commune"],
                    "departement": top_opportunity["code_departement"],
                    "score": top_opportunity["score_global"],
                    "rendement": top_opportunity["rendement_brut"],
                    "prix_moyen": top_opportunity["prix_moyen"],
                },
                "points_forts": [
                    f"Score d'investissement: {top_opportunity['score_global']:.1f}/10",
                    f"Rendement estim√©: {top_opportunity['rendement_brut']:.1f}%",
                    f"Cat√©gorie: {top_opportunity['categorie_zone']}",
                ],
            }

            summary["principales_opportunites"] = principales_opportunites

        # Analyse des risques
        risk_analysis = {
            "zones_a_eviter": len(zones_data[zones_data["categorie_zone"] == "Zone √† √âviter"]),
            "zones_faible_liquidite": len(zones_data[zones_data["nb_transactions"] < 10]),
            "zones_rendement_faible": len(zones_data[zones_data["rendement_brut"] < 3]),
            "recommandations_risque": [
                "Privil√©gier les zones avec plus de 10 transactions annuelles",
                "√âviter les zones avec rendement < 3%",
                "Diversifier g√©ographiquement les investissements",
            ],
        }

        summary["analyse_risques"] = risk_analysis

        # Conseils strat√©giques
        strategic_advice = {
            "investisseur_debutant": [
                "Commencer par les zones 'Premium' ou 'Attractives'",
                "Privil√©gier un rendement de 4-6% pour commencer",
                "Choisir des biens de 50-80m¬≤ pour faciliter la location",
            ],
            "investisseur_experimente": [
                "Explorer les zones √©mergentes avec potentiel",
                "Consid√©rer des rendements de 6%+ pour plus de plus-value",
                "Diversifier sur plusieurs d√©partements",
            ],
            "tendances_marche": [
                f"Rendement moyen du march√©: {market_overview['rendement_moyen_marche']:.1f}%",
                f"{market_overview['zones_premium']} zones premium identifi√©es",
                "Opportunit√©s principalement en p√©riph√©rie des grandes m√©tropoles",
            ],
        }

        summary["conseils_strategiques"] = strategic_advice

        # Checklist pour l'investisseur
        investor_checklist = {
            "avant_achat": [
                "‚úì V√©rifier l'√©tat du march√© locatif local",
                "‚úì Estimer les frais de r√©novation n√©cessaires",
                "‚úì Calculer la rentabilit√© nette (charges comprises)",
                "‚úì V√©rifier les projets d'am√©nagement du territoire",
                "‚úì Analyser la d√©mographie et l'emploi local",
            ],
            "criteres_selection": [
                "‚úì Score d'investissement > 5/10",
                "‚úì Rendement brut > 4%",
                "‚úì Zone avec > 10 transactions/an",
                "‚úì Prix en dessous de la moyenne locale",
                "‚úì Surface adapt√©e au march√© locatif (30-120m¬≤)",
            ],
            "apres_achat": [
                "‚úì Optimiser la fiscalit√© (r√©gime micro-BIC ou r√©el)",
                "‚úì Souscrire les assurances appropri√©es",
                "‚úì Mettre en place une gestion locative efficace",
                "‚úì Surveiller l'√©volution du march√© local",
                "‚úì Planifier les travaux de maintenance",
            ],
        }

        summary["checklist_investisseur"] = investor_checklist

        return summary
